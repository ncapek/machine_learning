{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern deep learning\n",
    "\n",
    "## Review - logistic regression code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and transforming data...\n",
      "Performing logistic regresion...\n",
      "Iter: 10/100,\n",
      " Train loss: 13844.380\n",
      "Train error: 0.096, Test loss: 408.819\n",
      "Test err: 0.110\n",
      "\n",
      "\n",
      "Iter: 20/100,\n",
      " Train loss: 12099.970\n",
      "Train error: 0.083, Test loss: 365.218\n",
      "Test err: 0.097\n",
      "\n",
      "\n",
      "Iter: 30/100,\n",
      " Train loss: 11420.852\n",
      "Train error: 0.078, Test loss: 352.185\n",
      "Test err: 0.094\n",
      "\n",
      "\n",
      "Iter: 40/100,\n",
      " Train loss: 11024.909\n",
      "Train error: 0.075, Test loss: 345.941\n",
      "Test err: 0.093\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_normalized_data, y2indicator, forward, cost, error_rate, predict, gradW, gradb\n",
    "\n",
    "\n",
    "def linear_benchmark():\n",
    "    Xtrain, Xtest, Ytrain, Ytest = get_normalized_data()\n",
    "    \n",
    "    print(\"Performing logistic regresion...\")\n",
    "    \n",
    "    # convert Ytrain and Ytest to (N x K) matrices of indicator variables\n",
    "    N, D = Xtrain.shape\n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    K = Ytrain_ind.shape[1]\n",
    "    \n",
    "    W = np.random.randn(D, K) / np.sqrt(D)\n",
    "    b = np.zeros(K)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_classification_errors = []\n",
    "    test_classification_errors = []\n",
    "    \n",
    "    lr = 0.00003\n",
    "    reg = 0.0\n",
    "    n_iters = 100\n",
    "    for i in range(n_iters):\n",
    "        p_y = forward(Xtrain, W, b)\n",
    "        train_loss = cost(p_y, Ytrain_ind)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        train_err = error_rate(p_y, Ytrain)\n",
    "        train_classification_errors.append(train_err)\n",
    "        \n",
    "        p_y_test = forward(Xtest, W, b)\n",
    "        test_loss = cost(p_y_test, Ytest_ind)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        test_err = error_rate(p_y_test, Ytest)\n",
    "        test_classification_errors.append(test_err)\n",
    "        \n",
    "        W += lr*(gradW(Ytrain_ind, p_y, Xtrain) - reg*W)\n",
    "        b += lr*gradb(Ytrain_ind, p_y)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Iter: {i+1}/{n_iters},\\n Train loss: {train_loss:.3f}\\n\"\n",
    "                  f\"Train error: {train_err:.3f}, Test loss: {test_loss:.3f}\\n\"\n",
    "                  f\"Test err: {test_err:.3f}\\n\\n\")\n",
    "    \n",
    "    p_y = forward(Xtest, W, b)\n",
    "    print(\"Final error rate\", error_rate(p_y, Ytest))\n",
    "    \n",
    "    plt.plot(train_losses, label='Train loss')\n",
    "    plt.plot(test_losses, label='Test loss')\n",
    "    plt.title(\"Loss per iteration\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(train_classification_errors, label='Train error')\n",
    "            \n",
    "linear_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
