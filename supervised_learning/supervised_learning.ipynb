{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning\n",
    "**If you can't implement it, you don't understand it**\n",
    "\n",
    "- topic covered: naive bayes, k nearest neighbors, perceptron, decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "- in this course we use the MNIST dataset available here: https://www.kaggle.com/c/digit-recognizer/overview\n",
    "- it consists of images of handwritten digits\n",
    "- inputs are a flattened vector of 28x28 pixels, no RGB so values are 0-255\n",
    "- input will be scaled to 0-1\n",
    "- targets are digits from 0 to 9\n",
    "- 42 000 images in the training set, test set doesn't come with labels on kaggle, so we will only be using the training set\n",
    "\n",
    "<img src=\"./assets/mnist.png\"\n",
    "     align=\"left\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest neighbors\n",
    "\n",
    "### Intuition\n",
    "- both simple conceptually and easy to implement in code  \n",
    "- sample problem:  \n",
    "    - will a student pass a course given that we know how many hours they studied?\n",
    "    - we have data about students from past semesters\n",
    "    - we can find students who are \"most similar\"\n",
    "    - similarity here is determined by the difference between how many hours they studied compared to other students\n",
    "    - by finding the most similar students, we can estimate performance based on their result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name  | Hours studied  | Passed   |\n",
    "|-------|---|---|\n",
    "| Alice | 1 | N |\n",
    "| Bob   | 3 | N |\n",
    "| Carol | 6 | Y |\n",
    "| David | 7 | Y |\n",
    "| Eric  | 8 | Y |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/knn1.png\"\n",
    "     alt=\"alt text\" \n",
    "     width=\"400\" \n",
    "     height=\"400\" \n",
    "     align=\"left\">     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using 2-nearest neighbours yields (Alice, Bob) who both failed, so the the prediction for the result would also be fail\n",
    "- using 3-nearest neighbours yields (Alice, Bob, Carol) which now has 1 instance of pass, in this case we would still predict the majority results, ie. fail\n",
    "- another possibility is to weigh the results based on distance \n",
    "- or to have a some other heuristic to break ties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts and implementation\n",
    "- given a $k$, find the $k$ nearest neighbours and use them to determine the prediction\n",
    "- finding the 1 nearest neighbour is simple:\n",
    "\n",
    "#### 1NN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(x_0):\n",
    "    '''\n",
    "    Given a single instance of input data, output the prediction\n",
    "    '''\n",
    "    closest_distance = inf\n",
    "    closest_class = -1\n",
    "    for x, y in training_data:\n",
    "        d = dist(x, x_0)\n",
    "        if d < closest_distance:\n",
    "            closest_distance = d\n",
    "            closest_class = y\n",
    "    return closest_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-neareset neighbours\n",
    "\n",
    "- keeping track of an arbitrary number of closest neighbours however is not so simple<br>\n",
    "- for every datapoint $i$ we need to find their respective $k$ nearest neighbours<br>\n",
    "example:\n",
    "    - $k = 3$ and we have stored distances [1, 2, 3]\n",
    "    - we encounter a point with distance 1.5, so we should replace the 3\n",
    "    - assuming we have $n$ datapoints in total, we need to look at all of them to make their respective prediction $\\implies \\mathcal{O(n)}$\n",
    "    - furthermore for every datapoint there is a list of $k$ closest neighbours, which needs to be iterated over to see if a datapoint should be updated $\\implies \\mathcal{O(k)}$\n",
    "    - in total then $\\implies \\mathcal{O(kn)}$\n",
    "    - improvements in complexity over the naive approach can be made by using a sorted list to hold the $k$ nearest neighbours $\\implies \\mathcal{O(n\\log{k})}$\n",
    "- knn is known as a lazy classifier - training consists only of storing data in memory, which is very fast, but predictions are slow<br>\n",
    "\n",
    "#### KNN Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and transforming data...\n",
      "[3.]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import get_data\n",
    "from sortedcontainers import SortedList\n",
    "# Note: can't use sorted dict, because the key is distance\n",
    "# when more points have same distance, they would be overwritten\n",
    "\n",
    "class KNN:\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        '''\n",
    "        Store \n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def predict(self, X_pred):\n",
    "        y = np.zeros(len(X_pred))\n",
    "        for i, x in enumerate(X_pred):\n",
    "            sort_list = SortedList()\n",
    "            for j, xt in enumerate(self.X):\n",
    "                diff = x - xt\n",
    "                d = diff.dot(diff.T)\n",
    "                if len(sort_list) < self.k:\n",
    "                    sort_list.add((d, self.y[j]))\n",
    "                else:\n",
    "                    if sort_list[-1][0]:\n",
    "                        del(sort_list[-1])\n",
    "                        sort_list.add((d, self.y[j]))\n",
    "            votes = {}\n",
    "            for _, v in sort_list:\n",
    "                votes[v] = votes.get(v, 0) + 1\n",
    "            max_votes = 0\n",
    "            max_votes_class = -1\n",
    "            for v, count in votes.items():\n",
    "                if count > max_votes:\n",
    "                    max_votes = count\n",
    "                    max_votes_class = v\n",
    "            y[i] = max_votes_class\n",
    "                    \n",
    "        return y\n",
    "\n",
    "X, Y = get_data()\n",
    "knn = KNN(5)\n",
    "knn.train(X, Y)\n",
    "print(knn.predict(np.array([X[:1]])))\n",
    "print(Y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "for el in x:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes and bayes classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
